### run this file after the preprocessing
### perform logistic regression locally


Logit <- function( X , y, lambda){
  X <- train_big
  y <- train_y
  X <- cbind(rep(1, dim(train_big)[1]), X)
  n <- dim(X)[1]
  p <- dim(X)[2]
  k <- dim(y)[2]
  m_nosadam <- 0
  v_nosadam <- 1
  p <- dim(X)[2]
  x <- matrix(1e-6, p, k-1)
  alpha_nosadam <- 5e-2
  beta_1 <- 0.9
  #times <- max_ite
  times <- 2000
  gamma <- 1e-2
  B <- cumsum((1:(1 + times*10))^(-gamma))
  loss <- rep(0, times)
  testloss <- rep(0, times*10)
  error <- rep(0, times*10)
  # lambda<-1e-1
  i <- 0
  
  flag = 0
  while (flag < times) {
    i <- i+1
    flag <- flag+1
    beta_2 <- B[i]/B[i+1] #0.99 #
    
    gradient <- Gradient(X,x,y) 
    tmp <- sqrt(rowSums(gradient^2)) > lambda
    
    gradient <- gradient -  (lambda * x/ sqrt(1e-6 + rowSums(x^2)) ) * (flag > 10)
    
    m_nosadam <- m_nosadam * beta_1 + (1-beta_1) * gradient
    v_nosadam <- v_nosadam * beta_2 + (1-beta_2) *gradient^2
    
    # lasso
    # tmp <- abs(gradient) > lambda
    # x <- tmp * ( x + alpha_nosadam / sqrt(i) * m_nosadam / sqrt(v_nosadam)      )
    # group lasso
    x <- tmp * ( x + alpha_nosadam/ sqrt(i)  * m_nosadam / sqrt(v_nosadam)      ) #
    
    n <- dim(test_big)[1]
    Beta <- cbind(rep(0,n),x)
    P0 <- exp(cbind(rep(1,n), test_big)%*%Beta)
    pred <- apply(P0,1, which.max)
    
    if(i%%20 == 0){
      loss[i] <- LOSS(X, x, y)
      testloss[i] <- mean(disease_vector[include_sample_test] == pred)
    }
    
  }
  result <- list()
  result$beta <- x
  result$loss <- loss[loss!=0]
  result$testloss <- testloss[testloss != 0]

  return(result)
}





# X<-train_big
# y<-train_y

Gradient <- function(X, x, y){
  P0 <- exp(X%*%x) # n by k-1
  P <<- P0/(rowSums(P0) + 1)
  return( t(X)%*% ( y[,-1] - P ) ) #p by k-1
}


LOSS <- function(X,x,y){
  P1 <- log(P)
  P1 <- cbind(log(1 - rowSums(P)), P1)
  sum( -P1*y   )
}




# k fold
set.seed(1)
k <- 8
testsize <- floor(sample_vector/k)

include_sample <- vector()

for( ii in 1:29){
  a <- sample(which(Train$event == inj_name[ii]), testsize[ii]*k)
  dim(a) <- c(k, testsize[ii])
  include_sample <- cbind(include_sample, a)
}

ii <- 33
a <- sample(which(Train$event == inj_name[ii]), testsize[ii]*k)
dim(a) <- c(k, testsize[ii])
include_sample <- cbind(include_sample, a)



ii <- 1
include_sample0 <- include_sample[ii, ]
train_big <- M_dgt[  include_sample0, ] 
train_y <- disease_factor[include_sample0, c(1:29,33)]
n <- dim(train_big)[1]
ii <- 2
include_sample_test <- include_sample[ii, ]
test_big <- M_dgt[  include_sample_test , ] 
test_y <- disease_factor[include_sample_test, c(1:29,33)]

result <- Logit(cbind(rep(1,n), train_big), train_y, lambda = 8e-1)
plot(result$loss)
plot(result$testloss)
#plot(result$loss[200:300])

#0.8 1000 times  0.783
#0.8 5000 times  0.796 x_5000



######## small smaple
ii <- 1
include_sample0 <- smallsample[1:15000]
train_big <- M_dgt[  include_sample0 ,] 
train_y <- disease_factor[include_sample0, c(1:29,33)]
n <- dim(train_big)[1]
ii <- 2
include_sample_test <- smallsample[15000:24000]
test_big <- M_dgt[  include_sample_test , ] 
test_y <- disease_factor[include_sample_test, c(1:29,33)]

#test accuracy
n <- dim(test_big)[1]
Beta <- cbind(rep(0,n), result$beta)
P <- exp(cbind(rep(1,n), test_big)%*%Beta)
pred <- apply(P, 1, which.max)
mean(disease_vector[include_sample0] == pred)


### train accuracy
n <- dim(train_big)[1]
Beta <- cbind(rep(0,n), result$beta)
P <- exp( cbind(rep(1,n), train_big) %*%Beta)
pred <- apply(P, 1, which.max)

mean(disease_vector[include_sample0] == pred)

### F1 score
a <- table(disease_vector[include_sample_test], pred)
n <- dim(a)[1]
fscore <- rep(0,n)
for (ii  in 1:n) {
  fscore[ii] <- 2*a[ii,ii]/(sum(a[ii,]) + sum(a[,ii])) 
}
sum(fscore*rowSums(a))/sum(rowSums(a))
fscore


#### result from cluster
testlossm1 <- c(0.5374668, 0.6411326, 0.6800855, 0.7000574, 0.7098608, 0.7202899, 0.7260781,
0.7317099, 0.7365073, 0.7401575, 0.7434948, 0.7454764, 0.7480315, 0.7494916,
0.7506909, 0.7515253, 0.7530375, 0.7535068, 0.7534025, 0.7543411, 0.7555926,
0.7566877, 0.7570006, 0.7579392, 0.7585649, 0.7591386, 0.7593471, 0.7600772,
0.7601815, 0.7601293, 0.7601293, 0.7599207, 0.7602336, 0.7604943, 0.7619023,
0.7619023, 0.7621630, 0.7627366, 0.7628930, 0.7634667, 0.7633624, 0.7637274,
0.7637274, 0.7634667, 0.7635709, 0.7637274, 0.7644053, 0.7648224, 0.7650310,
0.7652918, 0.7653960, 0.7655003, 0.7656568, 0.7661261, 0.7661782, 0.7661782,
0.7666475, 0.7668040, 0.7666997, 0.7669083, 0.7669083, 0.7671169, 0.7669083,
0.7672212, 0.7672212, 0.7677426, 0.7679512, 0.7683162, 0.7683684, 0.7682119,
0.7681598, 0.7681598, 0.7685248, 0.7685248, 0.7683162, 0.7686291, 0.7685769,
0.7683162, 0.7683684, 0.7685248, 0.7692548, 0.7693070, 0.7692548, 0.7694113,
0.7692548, 0.7693591, 0.7692027, 0.7695156, 0.7694113, 0.7696720, 0.7698284,
0.7700370, 0.7698806, 0.7701935, 0.7703499, 0.7704020, 0.7707149, 0.7710799,
0.7710799, 0.7706628, 0.7711842, 0.7707671, 0.7705063, 0.7707671, 0.7708192,
0.7709756, 0.7705585, 0.7708192, 0.7705585, 0.7708714, 0.7710799, 0.7716014,
0.7714971, 0.7714450, 0.7717057, 0.7718621, 0.7718100, 0.7722271, 0.7721750,
0.7723836, 0.7722271, 0.7724357, 0.7731658, 0.7731658, 0.7728008, 0.7729050,
0.7730615, 0.7731136, 0.7732701, 0.7731658, 0.7732701, 0.7732701, 0.7736872,
0.7735308, 0.7733222, 0.7734265, 0.7735829, 0.7730615, 0.7730615, 0.7730093,
0.7730615, 0.7732701, 0.7731658, 0.7729050, 0.7727486, 0.7726443, 0.7728008,
0.7727486, 0.7726443, 0.7728008, 0.7726965, 0.7729050, 0.7730093, 0.7733744,
0.7729050, 0.7729050, 0.7730615, 0.7735829, 0.7738958, 0.7736351, 0.7737394,
0.7737394, 0.7737915, 0.7738437, 0.7736872, 0.7735829, 0.7736872, 0.7738437,
0.7741565, 0.7741565, 0.7740523, 0.7738437, 0.7736872, 0.7736872, 0.7740523,
0.7740001, 0.7741565, 0.7746780, 0.7744694, 0.7746780, 0.7744694, 0.7742608,
0.7737394, 0.7741565, 0.7743130, 0.7743651, 0.7742087, 0.7743130, 0.7744173,
0.7746780, 0.7746780, 0.7748866, 0.7753559, 0.7753037, 0.7760338, 0.7759816,
0.7759295, 0.7765031, 0.7764510, 0.7766595, 0.7766074, 0.7758774, 0.7760859,
0.7758252, 0.7758774, 0.7757209, 0.7751995, 0.7753037, 0.7755123, 0.7753559,
0.7755645, 0.7757731, 0.7756688, 0.7755645, 0.7756688, 0.7755123, 0.7754602,
0.7756166, 0.7757209, 0.7757731, 0.7761902, 0.7761902, 0.7760859, 0.7767117,
0.7768681, 0.7767117, 0.7766074, 0.7760859, 0.7763988, 0.7769203, 0.7767117,
0.7766074, 0.7766074, 0.7769724, 0.7769724, 0.7767638, 0.7767117, 0.7768681,
0.7770246, 0.7771810, 0.7770246, 0.7775460, 0.7773896, 0.7771289, 0.7771289,
0.7768160, 0.7768160, 0.7769203, 0.7767638, 0.7768681, 0.7770767, 0.7766074,
0.7772331, 0.7771289, 0.7771289, 0.7779632, 0.7781718, 0.7781196, 0.7783282,
0.7786411, 0.7783804, 0.7784846, 0.7784325, 0.7776503, 0.7779632, 0.7784846,
0.7783282, 0.7785368, 0.7784325, 0.7784325, 0.7785889, 0.7786411, 0.7785889,
0.7785889, 0.7787454, 0.7788497, 0.7785368, 0.7783804, 0.7780675, 0.7780153,
0.7778067, 0.7780153, 0.7770767, 0.7770246, 0.7771810, 0.7769724, 0.7769203,
0.7770246, 0.7770767, 0.7771810, 0.7770246, 0.7770246, 0.7773896, 0.7775982,
0.7773896, 0.7777025, 0.7777025, 0.7779632, 0.7778589, 0.7777025, 0.7776503,
0.7782239, 0.7780675, 0.7780153, 0.7781718, 0.7782761, 0.7785368, 0.7787454,
0.7792147, 0.7794754, 0.7786932, 0.7785889, 0.7783282, 0.7781196, 0.7775982,
0.7777025, 0.7780153, 0.7781196, 0.7782239, 0.7780675, 0.7778589, 0.7783282,
0.7781718, 0.7778589, 0.7777025, 0.7778589, 0.7775982, 0.7774939, 0.7775460,
0.7774417, 0.7772853, 0.7771810, 0.7774939, 0.7774417, 0.7773896, 0.7772331,
0.7769203, 0.7768681, 0.7769203, 0.7768681, 0.7770246, 0.7769203, 0.7771810,
0.7772853, 0.7773374, 0.7772853, 0.7773374, 0.7773374, 0.7769203, 0.7767638,
0.7769203, 0.7775460, 0.7771289, 0.7773896, 0.7774939, 0.7781718, 0.7781718,
0.7779110, 0.7778589, 0.7783282, 0.7788497, 0.7789540, 0.7789018, 0.7786411,
0.7781196, 0.7786411, 0.7787454, 0.7787454, 0.7779110, 0.7780153, 0.7778589,
0.7782239, 0.7781718, 0.7783804, 0.7785889, 0.7786932, 0.7784846, 0.7778067,
0.7780153, 0.7781196, 0.7779110, 0.7777546, 0.7772853, 0.7774417, 0.7778589,
0.7777546, 0.7772853, 0.7774417, 0.7774939, 0.7776503, 0.7775982, 0.7777546,
0.7779632, 0.7780153, 0.7780675, 0.7780675, 0.7785368, 0.7783282, 0.7768160,
0.7770246, 0.7763467, 0.7763988, 0.7768681, 0.7770246, 0.7774417, 0.7773374,
0.7772853, 0.7779110, 0.7777025, 0.7774939, 0.7775460, 0.7775460, 0.7775982,
0.7770767, 0.7770246, 0.7772331, 0.7763467, 0.7768681, 0.7767117, 0.7767117,
0.7772853, 0.7765552, 0.7768681, 0.7765031, 0.7762945, 0.7762945, 0.7762424,
0.7766595, 0.7767117, 0.7768160, 0.7774417, 0.7774417, 0.7775460, 0.7775460,
0.7768160, 0.7769203, 0.7771810, 0.7775460, 0.7773896, 0.7773896, 0.7776503,
0.7774417, 0.7773374, 0.7775460, 0.7774417, 0.7775460, 0.7775982, 0.7773896,
0.7779110, 0.7774417, 0.7773374, 0.7772853, 0.7773896, 0.7772331, 0.7767638,
0.7762945, 0.7760338, 0.7762424, 0.7760859, 0.7764510, 0.7766074, 0.7766595,
0.7775460, 0.7774939, 0.7774939, 0.7770767, 0.7769203, 0.7771289, 0.7773896,
0.7743651, 0.7750952, 0.7758252, 0.7759816, 0.7760859, 0.7758252, 0.7764510,
0.7762945, 0.7760859, 0.7763467, 0.7761902, 0.7761902, 0.7766074, 0.7763467,
0.7763988, 0.7765552, 0.7765031, 0.7762945, 0.7766074, 0.7769724, 0.7768681,
0.7772853, 0.7770246, 0.7767117, 0.7768681, 0.7771810, 0.7772331, 0.7773374,
0.7772331, 0.7772331, 0.7771289)

testloss1<-c(0.5323565, 0.6347187, 0.6727851, 0.6931220, 0.7067842, 0.7175783, 0.7257131,
0.7321792, 0.7357251, 0.7400532, 0.7435991, 0.7481879, 0.7509517, 0.7515774,
0.7537154, 0.7554883, 0.7581478, 0.7594514, 0.7602858, 0.7617458, 0.7632581,
0.7646139, 0.7654482, 0.7666475, 0.7666475, 0.7678990, 0.7680033, 0.7691505,
0.7696199, 0.7695677, 0.7700892, 0.7700892, 0.7699327, 0.7705063, 0.7720186,
0.7716014, 0.7718100, 0.7729050, 0.7737394, 0.7743130, 0.7740001, 0.7746780,
0.7747823, 0.7757209, 0.7757731, 0.7750952, 0.7750430, 0.7753037, 0.7750952,
0.7751995, 0.7771289, 0.7768681, 0.7774417, 0.7769724, 0.7773896, 0.7771289,
0.7770767, 0.7767117, 0.7770767, 0.7774417, 0.7771289, 0.7777025, 0.7785368,
0.7754080, 0.7750430, 0.7754080, 0.7758774, 0.7763467, 0.7769724, 0.7774939,
0.7772331, 0.7776503, 0.7777025, 0.7781196, 0.7783804, 0.7791104, 0.7791625,
0.7796840, 0.7787454, 0.7789018, 0.7779110, 0.7776503, 0.7767117, 0.7762945,
0.7770246, 0.7770246, 0.7779632, 0.7788497, 0.7783282, 0.7771810, 0.7773896,
0.7779632, 0.7784846, 0.7782761, 0.7784846, 0.7784325, 0.7770246, 0.7780675,
0.7784846, 0.7787975, 0.7787454, 0.7790061, 0.7792668, 0.7793190, 0.7796840,
0.7802576, 0.7805183, 0.7804140, 0.7809355, 0.7803619, 0.7807791, 0.7815612,
0.7819784, 0.7823956, 0.7815091, 0.7815091, 0.7816655, 0.7774939, 0.7772331,
0.7777025, 0.7773374, 0.7779110, 0.7781718, 0.7784325, 0.7780675, 0.7785889,
0.7796840, 0.7787454, 0.7797361, 0.7802576, 0.7808312, 0.7811962, 0.7818220,
0.7822913, 0.7806748, 0.7804140, 0.7811441, 0.7809876, 0.7818741, 0.7820306,
0.7793190, 0.7783804, 0.7789540, 0.7790061, 0.7790582, 0.7796840, 0.7795276,
0.7778589, 0.7788497, 0.7791625, 0.7787975, 0.7794754, 0.7713407, 0.7724357,
0.7744694, 0.7755645, 0.7754602, 0.7751473, 0.7752516, 0.7767638, 0.7771810,
0.7775982, 0.7780675, 0.7778589, 0.7782239, 0.7790061, 0.7796319, 0.7805705,
0.7805183, 0.7812484, 0.7786411, 0.7783282, 0.7787454, 0.7793711, 0.7796319,
0.7802055, 0.7814048, 0.7816134, 0.7821870, 0.7803619, 0.7803097, 0.7810398,
0.7803619, 0.7801533, 0.7808833, 0.7813005, 0.7818220, 0.7810919, 0.7811441,
0.7810919, 0.7818741, 0.7819263, 0.7820306, 0.7764510, 0.7768681, 0.7774417,
0.7724879, 0.7723314, 0.7713928, 0.7712885, 0.7725400, 0.7735829, 0.7716535,
0.7725922, 0.7739480, 0.7737915, 0.7740523, 0.7748866, 0.7754080, 0.7732701,
0.7731136, 0.7731136, 0.7740523, 0.7748866, 0.7759816, 0.7767117, 0.7770767,
0.7772331, 0.7762945, 0.7762424, 0.7771810, 0.7780675, 0.7784325, 0.7795797,
0.7801533, 0.7805705, 0.7804140, 0.7785889, 0.7794233, 0.7799447, 0.7804662,
0.7790582, 0.7794233, 0.7794754, 0.7799969, 0.7803097, 0.7810919, 0.7817177,
0.7813005, 0.7798404, 0.7700370, 0.7707671, 0.7725922, 0.7728008, 0.7742608,
0.7749909, 0.7758252, 0.7777546, 0.7783282, 0.7781718, 0.7789540, 0.7788497,
0.7796840, 0.7797361, 0.7777025, 0.7777025, 0.7778589, 0.7782761, 0.7775460,
0.7778589, 0.7782761, 0.7789540, 0.7795797, 0.7797361, 0.7804662, 0.7807791,
0.7772331, 0.7771289, 0.7775460, 0.7781196, 0.7781718, 0.7785889, 0.7787454,
0.7793190, 0.7782239, 0.7778067, 0.7778589, 0.7781718, 0.7779632, 0.7777546,
0.7783282, 0.7788497, 0.7794233, 0.7755645, 0.7764510, 0.7775460, 0.7760859,
0.7774417, 0.7759295, 0.7773896, 0.7782761, 0.7790061, 0.7786932, 0.7795797,
0.7798926, 0.7801533, 0.7710278, 0.7726965, 0.7739480, 0.7747823, 0.7765031,
0.7774939, 0.7782239, 0.7779632, 0.7786932, 0.7794233, 0.7803097, 0.7786932,
0.7791104, 0.7798926, 0.7800490, 0.7801533, 0.7798926, 0.7792668, 0.7799447,
0.7804140, 0.7807791, 0.7798926, 0.7801012, 0.7806748, 0.7813527, 0.7791104,
0.7773374, 0.7781718, 0.7783282, 0.7793190, 0.7799447, 0.7780675, 0.7778589,
0.7788497, 0.7801012, 0.7798926, 0.7797361, 0.7794754, 0.7797361, 0.7807791,
0.7817177, 0.7817698, 0.7813527, 0.7778589, 0.7791104, 0.7793711, 0.7803619,
0.7797361, 0.7804140, 0.7805705, 0.7808312, 0.7813527, 0.7813005, 0.7816655,
0.7822391, 0.7816134, 0.7824477, 0.7822913, 0.7810398, 0.7820306, 0.7824999,
0.7830735, 0.7834385, 0.7842207, 0.7846378, 0.7845857, 0.7843771, 0.7830735,
0.7829692, 0.7796840, 0.7811962, 0.7816134, 0.7821348, 0.7829170, 0.7829692,
0.7794233, 0.7799969, 0.7803097, 0.7806748, 0.7806226, 0.7808312, 0.7783282,
0.7787454, 0.7790582, 0.7796840, 0.7801533, 0.7803619, 0.7805183, 0.7790061,
0.7798926, 0.7810398, 0.7814048, 0.7815091, 0.7817177, 0.7768160, 0.7790061,
0.7801533, 0.7805705, 0.7813527, 0.7811962, 0.7817698, 0.7817698, 0.7821348,
0.7824477, 0.7824477, 0.7826563, 0.7827085, 0.7835949, 0.7835428, 0.7806748,
0.7806748, 0.7809876, 0.7813527, 0.7816655, 0.7814570, 0.7819263, 0.7821348,
0.7822913, 0.7817177, 0.7819263, 0.7816134, 0.7819784, 0.7818741, 0.7821348,
0.7825520, 0.7823956, 0.7824999, 0.7830213, 0.7831256, 0.7833863, 0.7834906,
0.7835949, 0.7836992, 0.7812484, 0.7786411, 0.7755645, 0.7746780, 0.7755645,
0.7766595, 0.7763988, 0.7773374, 0.7786932, 0.7791104, 0.7790582, 0.7796319,
0.7799447, 0.7803619, 0.7804140, 0.7806748, 0.7798926, 0.7791625, 0.7797883,
0.7800490, 0.7804662, 0.7806748, 0.7810398, 0.7811441, 0.7812484, 0.7813005,
0.7810398, 0.7749909, 0.7713928, 0.7731136, 0.7717578, 0.7720707, 0.7733222,
0.7741565, 0.7747301, 0.7725400, 0.7729572, 0.7743651, 0.7753559, 0.7753559,
0.7696199, 0.7682119, 0.7687855, 0.7703499, 0.7709235, 0.7717578, 0.7724357,
0.7733744, 0.7736872, 0.7738958, 0.7701935, 0.7708714, 0.7694113, 0.7708714,
0.7720707, 0.7708714, 0.7720186, 0.7735308, 0.7676905, 0.7708714, 0.7721750,
0.7727486, 0.7735829, 0.7692548, 0.7705585, 0.7716014, 0.7726965, 0.7741565,
0.7748866, 0.7757209, 0.7760859)

testloss0<-c(0.5354331, 0.6404547, 0.6798248, 0.7004224, 0.7119466, 0.7211764, 0.7286333,
0.7347865, 0.7389581, 0.7432341, 0.7457371, 0.7474579, 0.7498045, 0.7512645,
0.7529332, 0.7549147, 0.7562705, 0.7584085, 0.7595036, 0.7612765, 0.7615894,
0.7631016, 0.7635709, 0.7647703, 0.7656568, 0.7659175, 0.7662304, 0.7674297,
0.7680555, 0.7683684, 0.7691505, 0.7697763, 0.7695677, 0.7695677, 0.7700892,
0.7704542, 0.7705585, 0.7713928, 0.7712364, 0.7722793, 0.7727486, 0.7732701,
0.7733222, 0.7731136, 0.7735829, 0.7742087, 0.7734786, 0.7736872, 0.7742608,
0.7744173, 0.7747301, 0.7749387, 0.7754602, 0.7754080, 0.7760338, 0.7763988,
0.7760859, 0.7760338, 0.7761902, 0.7758774, 0.7762945, 0.7768160, 0.7771289,
0.7776503, 0.7784846, 0.7785368, 0.7789018, 0.7791104, 0.7794233, 0.7795797,
0.7796319, 0.7802576, 0.7803619, 0.7805183, 0.7807791, 0.7807791, 0.7810919,
0.7806226, 0.7806226, 0.7807269, 0.7807269, 0.7815612, 0.7809876, 0.7807269,
0.7809355, 0.7814048, 0.7814570, 0.7819784, 0.7818220, 0.7821348, 0.7818220,
0.7818220, 0.7820306, 0.7822391, 0.7827606, 0.7828649, 0.7823434, 0.7826563,
0.7829692, 0.7831256, 0.7832299, 0.7826563, 0.7827085, 0.7823434, 0.7831256,
0.7831256, 0.7820306, 0.7822913, 0.7822913, 0.7828127, 0.7833863, 0.7835428,
0.7827606, 0.7834906, 0.7836471, 0.7836471, 0.7838035, 0.7834906, 0.7836992,
0.7831256, 0.7824999, 0.7827085, 0.7828127, 0.7826563, 0.7824999, 0.7829170,
0.7829692, 0.7829692, 0.7831778, 0.7824999, 0.7831778, 0.7831256, 0.7835949,
0.7838035, 0.7837514, 0.7838557, 0.7842207, 0.7846378, 0.7837514, 0.7831778,
0.7836471, 0.7840642, 0.7841164, 0.7848986, 0.7855243, 0.7859415, 0.7862544,
0.7862022, 0.7859936, 0.7858372, 0.7856808, 0.7853157, 0.7847943, 0.7848464,
0.7850550, 0.7852115, 0.7854200, 0.7855243, 0.7854200, 0.7855765, 0.7856808,
0.7858893, 0.7856808, 0.7855765, 0.7855243, 0.7855243, 0.7855243, 0.7858372,
0.7855243, 0.7856286, 0.7850029, 0.7854200, 0.7850029, 0.7841164, 0.7844293,
0.7841685, 0.7845857, 0.7849507, 0.7852115, 0.7853157, 0.7851072, 0.7852636,
0.7855243, 0.7856286, 0.7857851, 0.7856808, 0.7857329, 0.7863587, 0.7860979,
0.7854200, 0.7854722, 0.7855243, 0.7845857, 0.7845857, 0.7848986, 0.7843250,
0.7849507, 0.7847943, 0.7838557, 0.7838557, 0.7842207, 0.7846378, 0.7848464,
0.7843250, 0.7842207, 0.7850029, 0.7845336, 0.7849507, 0.7847943, 0.7853157,
0.7849507, 0.7850029, 0.7856808, 0.7855243, 0.7856808, 0.7857851, 0.7851593,
0.7849507, 0.7850550, 0.7825520, 0.7820306, 0.7822391, 0.7828127, 0.7820827,
0.7820306, 0.7815612, 0.7822391, 0.7825520, 0.7828649, 0.7828649, 0.7826042,
0.7828649, 0.7832821, 0.7835428, 0.7834906, 0.7834906, 0.7838557, 0.7833863,
0.7830213, 0.7831778, 0.7834385, 0.7841685, 0.7845336, 0.7846378, 0.7850029,
0.7851593, 0.7857851, 0.7856808, 0.7862022, 0.7865672, 0.7865151, 0.7858893,
0.7854722, 0.7859415, 0.7858893, 0.7859936, 0.7859415, 0.7858893, 0.7862022,
0.7859415, 0.7842207, 0.7841164, 0.7844293, 0.7846378, 0.7848986, 0.7850550,
0.7853679, 0.7804662, 0.7809876, 0.7813527, 0.7812484, 0.7818220, 0.7826042,
0.7816655, 0.7822913, 0.7802055, 0.7808312, 0.7818220, 0.7817698, 0.7819263,
0.7824477, 0.7826563, 0.7831778, 0.7832299, 0.7835949, 0.7836471, 0.7835949,
0.7839078, 0.7833342, 0.7827085, 0.7825520, 0.7824999, 0.7827606, 0.7831778,
0.7830213, 0.7833863, 0.7834906, 0.7840642, 0.7840642, 0.7848464, 0.7846378,
0.7843250, 0.7847943, 0.7848986, 0.7849507, 0.7852636, 0.7843771, 0.7844814,
0.7850550, 0.7854200, 0.7855243, 0.7853157, 0.7856808, 0.7850550, 0.7855243,
0.7856286, 0.7859415, 0.7859415, 0.7856808, 0.7850550, 0.7859415, 0.7858893,
0.7856808, 0.7859415, 0.7857329, 0.7847421, 0.7847421, 0.7852636, 0.7853157,
0.7849507, 0.7850029, 0.7855765, 0.7855243, 0.7856808, 0.7863065, 0.7863065,
0.7866194, 0.7840121, 0.7839078, 0.7839078, 0.7829692, 0.7828649, 0.7832821,
0.7834906, 0.7834385, 0.7842207, 0.7840121, 0.7841164, 0.7842728, 0.7844814,
0.7846378, 0.7831778, 0.7832299, 0.7832299, 0.7833863, 0.7836471, 0.7838557,
0.7840121, 0.7840121, 0.7835428, 0.7838557, 0.7842207, 0.7843250, 0.7836471,
0.7831256, 0.7835428, 0.7832821, 0.7834906, 0.7839600, 0.7843250, 0.7851593,
0.7851072, 0.7850029, 0.7850550, 0.7851593, 0.7783282, 0.7773374, 0.7784325,
0.7796840, 0.7779632, 0.7790582, 0.7797883, 0.7797361, 0.7809355, 0.7812484,
0.7814570, 0.7817698, 0.7818741, 0.7823956, 0.7815091, 0.7817177, 0.7819784,
0.7819263, 0.7824999, 0.7826042, 0.7825520, 0.7826563, 0.7829170, 0.7827606,
0.7827606, 0.7824999, 0.7827606, 0.7827085, 0.7829170, 0.7834385, 0.7832821,
0.7836471, 0.7835949, 0.7833863, 0.7844814, 0.7842728, 0.7845336, 0.7842207,
0.7841164, 0.7833863, 0.7836992, 0.7837514, 0.7838035, 0.7838557, 0.7839600,
0.7842728, 0.7843771, 0.7841164, 0.7844814, 0.7845857, 0.7833342, 0.7826563,
0.7834906, 0.7843771, 0.7840121, 0.7836992, 0.7830735, 0.7829170, 0.7830735,
0.7834385, 0.7838557, 0.7835949, 0.7837514, 0.7841685, 0.7843771, 0.7845857,
0.7843250, 0.7841685, 0.7847421, 0.7846900, 0.7845857, 0.7843250, 0.7847943,
0.7847943, 0.7848986, 0.7846378, 0.7835428, 0.7839600, 0.7840642, 0.7842207,
0.7843771, 0.7847943, 0.7848464, 0.7847943, 0.7846900, 0.7847943, 0.7822913,
0.7811441, 0.7817177, 0.7814570, 0.7817177, 0.7823434, 0.7828127, 0.7830735,
0.7835949, 0.7840642, 0.7843771, 0.7842207, 0.7843250, 0.7839078, 0.7844293,
0.7845336, 0.7843771, 0.7847421, 0.7819263, 0.7810919, 0.7819784, 0.7828649,
0.7833342, 0.7822391, 0.7825520, 0.7828127, 0.7807791, 0.7820306, 0.7827606,
0.7829692, 0.7825520, 0.7823956, 0.7830735, 0.7838557, 0.7839078, 0.7841685,
0.7839600, 0.7845336, 0.7846900)

plot(1:length(testloss1)*(20), testloss1,xlab = "iteration times", ylab = "test accuracy", main = "Accuracy v.s. iteration times", type = "l")
lines(1:length(testloss0)*(20), testloss0, col = 2)
lines(1:length(testlossm1)*(20), testlossm1, col = 3)

legend(5500, 0.73, col = c(1,2,3), legend = c("lambda=exp(1)", "lambda=exp(0)", "lambda=exp(-1)") , lty = c(1,1,1))
       
library(ggplot2)

iteration <- rep(1:500*20, times = 3)
type <- rep(c("lambda=exp(1)", "lambda=exp(0)", "lambda=exp(-1)"), each = 500)
Accuracy <- c(testloss1, testloss0, testlossm1)
df <- data.frame(iteration = iteration, type = type, Accuracy = Accuracy)
ggplot(data = df, mapping = aes(x = iteration, y = Accuracy, colour = type)) + 
  labs(title = "Accuracy of Logistic Regression") + coord_cartesian(ylim=c(0.7, 0.8)) + geom_line() +
  theme(plot.title = element_text(hjust = 0.5)) 

